{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lab5_1(a).ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"6NaAD8zpv2Yv","colab_type":"code","outputId":"c665b37c-f593-4dbf-e9c7-08abe919f54d","executionInfo":{"status":"ok","timestamp":1592130621920,"user_tz":-180,"elapsed":75431,"user":{"displayName":"Victoria Ilyina","photoUrl":"","userId":"07809839839950640169"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c3bJlWt3Vq_G","colab_type":"code","outputId":"ff39313c-a111-44cc-d39b-e788a89fd642","executionInfo":{"status":"ok","timestamp":1592130732749,"user_tz":-180,"elapsed":107739,"user":{"displayName":"Victoria Ilyina","photoUrl":"","userId":"07809839839950640169"}},"colab":{"base_uri":"https://localhost:8080/","height":860}},"source":["!pip3 uninstall tensorflow \n","!pip3 install tensorflow-gpu==1.14"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Uninstalling tensorflow-2.2.0:\n","  Would remove:\n","    /usr/local/bin/estimator_ckpt_converter\n","    /usr/local/bin/saved_model_cli\n","    /usr/local/bin/tensorboard\n","    /usr/local/bin/tf_upgrade_v2\n","    /usr/local/bin/tflite_convert\n","    /usr/local/bin/toco\n","    /usr/local/bin/toco_from_protos\n","    /usr/local/lib/python3.6/dist-packages/tensorflow-2.2.0.dist-info/*\n","    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n","Proceed (y/n)? y\n","  Successfully uninstalled tensorflow-2.2.0\n","Collecting tensorflow-gpu==1.14\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/04/43153bfdfcf6c9a4c38ecdb971ca9a75b9a791bb69a764d652c359aca504/tensorflow_gpu-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (377.0MB)\n","\u001b[K     |████████████████████████████████| 377.0MB 38kB/s \n","\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.3.3)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.1.2)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.0.8)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.9.0)\n","Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.18.5)\n","Collecting tensorboard<1.15.0,>=1.14.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 38.5MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.12.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (3.10.0)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.2.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.1.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.8.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.34.2)\n","Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n","\u001b[K     |████████████████████████████████| 491kB 40.6MB/s \n","\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.29.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.12.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14) (2.10.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (47.1.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (3.2.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (1.0.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (1.6.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (3.1.0)\n","Installing collected packages: tensorboard, tensorflow-estimator, tensorflow-gpu\n","  Found existing installation: tensorboard 2.2.2\n","    Uninstalling tensorboard-2.2.2:\n","      Successfully uninstalled tensorboard-2.2.2\n","  Found existing installation: tensorflow-estimator 2.2.0\n","    Uninstalling tensorflow-estimator-2.2.0:\n","      Successfully uninstalled tensorflow-estimator-2.2.0\n","Successfully installed tensorboard-1.14.0 tensorflow-estimator-1.14.0 tensorflow-gpu-1.14.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bFBz8AdxWlQB","colab_type":"code","outputId":"1ce5cc2c-c2c6-483e-9530-86c3b23fbeca","executionInfo":{"status":"ok","timestamp":1592130893211,"user_tz":-180,"elapsed":2676,"user":{"displayName":"Victoria Ilyina","photoUrl":"","userId":"07809839839950640169"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import os\n","os.chdir(\"/content/drive/My Drive/СМОМИ/Лаба 5\")\n","!ls"],"execution_count":4,"outputs":[{"output_type":"stream","text":[" images  'lab3(3)(1).ipynb'   logs   modelB.h5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"j1q2xvl1iqlf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"b9cd6184-55e8-4741-968e-adc80e76cfea","executionInfo":{"status":"error","timestamp":1592133051434,"user_tz":-180,"elapsed":2154274,"user":{"displayName":"Victoria Ilyina","photoUrl":"","userId":"07809839839950640169"}}},"source":["__author__ = 'Alexander Soroka, soroka.a.m@gmail.com'\n","__copyright__ = \"\"\"Copyright 2020 Alexander Soroka\"\"\"\n","\n","\n","import math\n","import random\n","import argparse\n","import glob\n","import numpy as np\n","import tensorflow as tf\n","import time\n","from tensorflow.python import keras as keras\n","from tensorflow.python.keras.callbacks import LearningRateScheduler\n","\n","LOG_DIR = 'logs'\n","SHUFFLE_BUFFER = 10\n","BATCH_SIZE = 8\n","NUM_CLASSES = 2\n","PARALLEL_CALLS=4\n","RESIZE_TO = 224\n","TRAINSET_SIZE = 5216\n","VALSET_SIZE=624\n","\n","\n","def parse_proto_example(proto):\n","    keys_to_features = {\n","        'image/encoded': tf.FixedLenFeature((), tf.string, default_value=''),\n","        'image/class/label': tf.FixedLenFeature([], tf.int64, default_value=tf.zeros([], dtype=tf.int64))\n","    }\n","    example = tf.parse_single_example(proto, keys_to_features)\n","    example['image'] = tf.image.decode_jpeg(example['image/encoded'], channels=3)\n","    example['image'] = tf.image.convert_image_dtype(example['image'], dtype=tf.float32)\n","    example['image'] = tf.image.resize_images(example['image'], tf.constant([RESIZE_TO, RESIZE_TO]))\n","    return example['image'], example['image/class/label']\n","\n","\n","def normalize(image, label):\n","    return tf.image.per_image_standardization(image), label\n","\n","def resize(image, label):\n","    return tf.image.resize_images(image, tf.constant([RESIZE_TO, RESIZE_TO])), label\n","\n","def create_dataset(filenames, batch_size):\n","    \"\"\"Create dataset from tfrecords file\n","    :tfrecords_files: Mask to collect tfrecords file of dataset\n","    :returns: tf.data.Dataset\n","    \"\"\"\n","    return tf.data.TFRecordDataset(filenames)\\\n","        .map(parse_proto_example)\\\n","        .map(resize)\\\n","        .map(normalize)\\\n","        .shuffle(buffer_size=5 * batch_size)\\\n","        .repeat()\\\n","        .batch(batch_size)\\\n","        .prefetch(2 * batch_size)\n","\n","def create_augmented_dataset(filenames, batch_size):\n","    \"\"\"Create dataset from tfrecords file\n","    :tfrecords_files: Mask to collect tfrecords file of dataset\n","    :returns: tf.data.Dataset\n","    \"\"\"\n","    return tf.data.TFRecordDataset(filenames)\\\n","        .map(parse_proto_example)\\\n","        .map(augment)\\\n","        .map(resize)\\\n","        .map(normalize)\\\n","        .shuffle(buffer_size=5 * batch_size)\\\n","        .repeat()\\\n","        .batch(batch_size)\\\n","        .prefetch(2 * batch_size)\n","\n","def augment(image, label):\n","\n","    degree = 10\n","    dgr = random.uniform(-degree, degree)\n","    image = tf.image.convert_image_dtype(image, tf.float32)\n","    image = tf.contrib.image.rotate(image, dgr * math.pi / 180, interpolation='BILINEAR')\n","    image = tf.image.random_flip_left_right(image)\n","    image = tf.image.random_brightness(image, 0.5, seed=None)\n","    image = tf.image.random_contrast(image, 0.4, 1.4, seed=None) \n","    image = tf.image.random_crop(image, size=[215, 215, 3], seed=None, name=None)  \n","    return image,label\n","\n","class Validation(tf.keras.callbacks.Callback):\n","    def __init__(self, log_dir, validation_files, batch_size):\n","        self.log_dir = log_dir\n","        self.validation_files = validation_files\n","        self.batch_size = batch_size\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        print('The average loss for epoch {} is {:7.2f} '.format(\n","            epoch, logs['loss']\n","        ))\n","\n","        validation_dataset = create_dataset(self.validation_files, self.batch_size)\n","        validation_images, validation_labels = validation_dataset.make_one_shot_iterator().get_next()\n","        validation_labels = tf.one_hot(validation_labels, NUM_CLASSES)\n","\n","        result = self.model.evaluate(\n","            validation_images,\n","            validation_labels,\n","            steps=int(np.ceil(VALSET_SIZE / float(BATCH_SIZE)))\n","        )\n","        callback = tf.keras.callbacks.TensorBoard(log_dir=self.log_dir, update_freq='epoch', batch_size=self.batch_size)\n","\n","        callback.set_model(self.model)\n","        callback.on_epoch_end(epoch, {\n","            'val_' + self.model.metrics_names[i]: v for i, v in enumerate(result)\n","        })\n","\n","def step_decay(epoch):\n","   initial_lrate = 0.0000000001\n","   drop = 0.5\n","   epochs_drop = 10.0\n","   lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n","   return lrate\n"," \n","\n","def build_model():\n","    model = keras.models.load_model('modelB.h5')\n","    model.trainable = True\n","    return model\n","     \n","\n","def main():\n","    train_path = './images/train*'\n","    test_path = './images/test*'\n","\n","    train_dataset = create_augmented_dataset(glob.glob(train_path), BATCH_SIZE)\n","    train_images, train_labels = train_dataset.make_one_shot_iterator().get_next()\n","    train_labels = tf.one_hot(train_labels, NUM_CLASSES)\n","\n","    lrate = LearningRateScheduler(step_decay)\n","\n","    model = build_model()\n","\n","    model.compile(\n","        optimizer=keras.optimizers.sgd(lr=0.0, momentum=0.9),\n","        loss=tf.keras.losses.categorical_crossentropy,\n","        metrics=[tf.keras.metrics.categorical_accuracy],\n","        target_tensors=[train_labels]\n","    )\n","\n","    log_dir='{}/xray-{}'.format(LOG_DIR, time.time())\n","    model.fit(\n","        (train_images, train_labels),\n","        epochs=120, \n","        steps_per_epoch=int(np.ceil(TRAINSET_SIZE / float(BATCH_SIZE))),\n","        callbacks=[\n","            lrate,\n","            tf.keras.callbacks.TensorBoard(log_dir),\n","            Validation(log_dir, validation_files=glob.glob(test_path), batch_size=BATCH_SIZE)\n","        ]\n","    )\n","\n","\n","if __name__ == '__main__':\n","    main()"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/image_ops_impl.py:1514: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Deprecated in favor of operator or tf.math.divide.\n","WARNING:tensorflow:From <ipython-input-5-81736af77bad>:115: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","Epoch 1/120\n","651/652 [============================>.] - ETA: 0s - loss: 0.0476 - categorical_accuracy: 0.4885The average loss for epoch 0 is    0.05 \n","78/78 [==============================] - 17s 216ms/step - loss: 0.0788 - categorical_accuracy: 0.2388\n","652/652 [==============================] - 119s 182ms/step - loss: 0.0475 - categorical_accuracy: 0.4881\n","Epoch 2/120\n","651/652 [============================>.] - ETA: 0s - loss: 0.0699 - categorical_accuracy: 0.5430The average loss for epoch 1 is    0.07 \n","78/78 [==============================] - 14s 175ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.1410\n","652/652 [==============================] - 112s 171ms/step - loss: 0.0698 - categorical_accuracy: 0.5424\n","Epoch 3/120\n","651/652 [============================>.] - ETA: 0s - loss: 0.0460 - categorical_accuracy: 0.5090The average loss for epoch 2 is    0.05 \n","78/78 [==============================] - 17s 224ms/step - loss: 0.1832 - categorical_accuracy: 0.4888\n","652/652 [==============================] - 109s 167ms/step - loss: 0.0460 - categorical_accuracy: 0.5090\n","Epoch 4/120\n","651/652 [============================>.] - ETA: 0s - loss: 0.0467 - categorical_accuracy: 0.5284The average loss for epoch 3 is    0.05 \n","78/78 [==============================] - 14s 175ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.1587\n","652/652 [==============================] - 105s 161ms/step - loss: 0.0467 - categorical_accuracy: 0.5282\n","Epoch 5/120\n","651/652 [============================>.] - ETA: 0s - loss: 0.0455 - categorical_accuracy: 0.5397The average loss for epoch 4 is    0.05 \n","78/78 [==============================] - 14s 176ms/step - loss: 0.0081 - categorical_accuracy: 0.1683\n","652/652 [==============================] - 105s 161ms/step - loss: 0.0454 - categorical_accuracy: 0.5397\n","Epoch 6/120\n","651/652 [============================>.] - ETA: 0s - loss: 0.0742 - categorical_accuracy: 0.6029The average loss for epoch 5 is    0.07 \n","78/78 [==============================] - 14s 174ms/step - loss: 0.0110 - categorical_accuracy: 0.1907\n","652/652 [==============================] - 112s 171ms/step - loss: 0.0744 - categorical_accuracy: 0.6035\n","Epoch 7/120\n","651/652 [============================>.] - ETA: 0s - loss: 0.0468 - categorical_accuracy: 0.5722The average loss for epoch 6 is    0.05 \n","78/78 [==============================] - 17s 216ms/step - loss: 0.1472 - categorical_accuracy: 0.3734\n","652/652 [==============================] - 106s 163ms/step - loss: 0.0468 - categorical_accuracy: 0.5723\n","Epoch 8/120\n","651/652 [============================>.] - ETA: 0s - loss: 0.0526 - categorical_accuracy: 0.5956The average loss for epoch 7 is    0.05 \n","78/78 [==============================] - 14s 176ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.2115\n","652/652 [==============================] - 106s 163ms/step - loss: 0.0526 - categorical_accuracy: 0.5957\n","Epoch 9/120\n","651/652 [============================>.] - ETA: 0s - loss: 0.0481 - categorical_accuracy: 0.6206The average loss for epoch 8 is    0.05 \n","78/78 [==============================] - 14s 174ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.2244\n","652/652 [==============================] - 105s 160ms/step - loss: 0.0480 - categorical_accuracy: 0.6202\n","Epoch 10/120\n","651/652 [============================>.] - ETA: 0s - loss: 0.0708 - categorical_accuracy: 0.6651The average loss for epoch 9 is    0.07 \n","78/78 [==============================] - 14s 178ms/step - loss: 0.0794 - categorical_accuracy: 0.3574\n","652/652 [==============================] - 111s 170ms/step - loss: 0.0710 - categorical_accuracy: 0.6656\n","Epoch 11/120\n","651/652 [============================>.] - ETA: 0s - loss: 0.0491 - categorical_accuracy: 0.6317The average loss for epoch 10 is    0.05 \n","78/78 [==============================] - 15s 192ms/step - loss: 0.0780 - categorical_accuracy: 0.2885\n","652/652 [==============================] - 107s 164ms/step - loss: 0.0490 - categorical_accuracy: 0.6321\n","Epoch 12/120\n","651/652 [============================>.] - ETA: 0s - loss: 0.0629 - categorical_accuracy: 0.6701The average loss for epoch 11 is    0.06 \n","78/78 [==============================] - 14s 173ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.2420\n","652/652 [==============================] - 106s 163ms/step - loss: 0.0628 - categorical_accuracy: 0.6704\n","Epoch 13/120\n","651/652 [============================>.] - ETA: 0s - loss: 0.0504 - categorical_accuracy: 0.6699The average loss for epoch 12 is    0.05 \n","78/78 [==============================] - 14s 175ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.2580\n","652/652 [==============================] - 105s 160ms/step - loss: 0.0503 - categorical_accuracy: 0.6699\n","Epoch 14/120\n","651/652 [============================>.] - ETA: 0s - loss: 0.0705 - categorical_accuracy: 0.7008The average loss for epoch 13 is    0.07 \n","78/78 [==============================] - 16s 202ms/step - loss: 0.1918 - categorical_accuracy: 0.4327\n","652/652 [==============================] - 112s 171ms/step - loss: 0.0709 - categorical_accuracy: 0.7013\n","Epoch 15/120\n","651/652 [============================>.] - ETA: 0s - loss: 0.0531 - categorical_accuracy: 0.6845The average loss for epoch 14 is    0.05 \n","78/78 [==============================] - 13s 172ms/step - loss: 0.0045 - categorical_accuracy: 0.2772\n","652/652 [==============================] - 105s 161ms/step - loss: 0.0530 - categorical_accuracy: 0.6842\n","Epoch 16/120\n","651/652 [============================>.] - ETA: 0s - loss: 0.0720 - categorical_accuracy: 0.7097The average loss for epoch 15 is    0.07 \n","78/78 [==============================] - 14s 175ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.2821\n","652/652 [==============================] - 107s 164ms/step - loss: 0.0719 - categorical_accuracy: 0.7101\n","Epoch 17/120\n","651/652 [============================>.] - ETA: 0s - loss: 0.0549 - categorical_accuracy: 0.7170The average loss for epoch 16 is    0.05 \n","78/78 [==============================] - 14s 175ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.3045\n","652/652 [==============================] - 105s 160ms/step - loss: 0.0548 - categorical_accuracy: 0.7166\n","Epoch 18/120\n","651/652 [============================>.] - ETA: 0s - loss: 0.0679 - categorical_accuracy: 0.7508The average loss for epoch 17 is    0.07 \n","78/78 [==============================] - 17s 219ms/step - loss: 0.3143 - categorical_accuracy: 0.4824\n","652/652 [==============================] - 110s 169ms/step - loss: 0.0685 - categorical_accuracy: 0.7510\n","Epoch 19/120\n","651/652 [============================>.] - ETA: 0s - loss: 0.0571 - categorical_accuracy: 0.7429The average loss for epoch 18 is    0.06 \n","78/78 [==============================] - 14s 178ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.3381\n","652/652 [==============================] - 106s 163ms/step - loss: 0.0570 - categorical_accuracy: 0.7429\n","Epoch 20/120\n","648/652 [============================>.] - ETA: 0s - loss: 0.0784 - categorical_accuracy: 0.7577"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-81736af77bad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-5-81736af77bad>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mlrate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mValidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         ]\n\u001b[1;32m    139\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m           \u001b[0;31m# `ins` can be callable in tf.distribute.Strategy + eager case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m           \u001b[0mactual_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mis_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}